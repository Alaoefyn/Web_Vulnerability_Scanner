import requests
from bs4 import BeautifulSoup

OUTDATED_JS_LIBRARIES = {
    'jquery': '3.6.0',  # Add more libraries and their latest versions if needed
}

def fetch_html(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
        return response.text
    except requests.RequestException as e:
        print(f"Error fetching {url}: {e}")
        return None

def scan_for_outdated_js(soup):
    vulnerabilities = []
    for script in soup.find_all('script'):
        if script.get('src'):
            src = script['src']
            for lib, latest_version in OUTDATED_JS_LIBRARIES.items():
                if lib in src:
                    version = src.split('/')[-1].replace('.js', '').split('-')[-1]
                    if version < latest_version:
                        vulnerabilities.append(f"Outdated {lib} version: {version}, latest is {latest_version}")
    return vulnerabilities

def scan_for_xss(soup):
    vulnerabilities = []
    for tag in soup.find_all(True):
        for attr in tag.attrs:
            if 'on' in attr.lower():
                vulnerabilities.append(f"Potential XSS vulnerability in {tag.name} tag, attribute: {attr}")
    return vulnerabilities

def scan_for_csrf_protection(soup):
    vulnerabilities = []
    forms = soup.find_all('form')
    for form in forms:
        if not form.find('input', {'name': 'csrf_token'}):
            vulnerabilities.append(f"Form at {form.get('action', 'unknown action')} missing CSRF token")
    return vulnerabilities

def scan_for_clickjacking(headers):
    vulnerabilities = []
    if 'X-Frame-Options' not in headers:
        vulnerabilities.append("Missing X-Frame-Options header, vulnerable to clickjacking")
    return vulnerabilities

def scan_for_insecure_links(soup):
    vulnerabilities = []
    for link in soup.find_all('a', href=True):
        if link['href'].startswith('http://'):
            vulnerabilities.append(f"Insecure link found: {link['href']}")
    return vulnerabilities

def scan_website(url):
    vulnerabilities = []
    html = fetch_html(url)
    if not html:
        return ["Error: Unable to fetch the website."]
    soup = BeautifulSoup(html, 'html.parser')
    vulnerabilities.extend(scan_for_outdated_js(soup))
    vulnerabilities.extend(scan_for_xss(soup))
    vulnerabilities.extend(scan_for_csrf_protection(soup))
    vulnerabilities.extend(scan_for_insecure_links(soup))
    try:
        response = requests.head(url)
        vulnerabilities.extend(scan_for_clickjacking(response.headers))
    except requests.RequestException as e:
        vulnerabilities.append(f"Error fetching headers for clickjacking check: {e}")
    return vulnerabilities if vulnerabilities else ["No vulnerabilities found."]
